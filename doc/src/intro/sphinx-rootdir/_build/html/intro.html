
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
  "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">


<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    
    <title>Introduction and Motivation</title>
    
    <link rel="stylesheet" href="_static/alabaster.css" type="text/css" />
    <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
    
    <script type="text/javascript">
      var DOCUMENTATION_OPTIONS = {
        URL_ROOT:    './',
        VERSION:     '1.0',
        COLLAPSE_INDEX: false,
        FILE_SUFFIX: '.html',
        HAS_SOURCE:  true
      };
    </script>
    <script type="text/javascript" src="_static/jquery.js"></script>
    <script type="text/javascript" src="_static/underscore.js"></script>
    <script type="text/javascript" src="_static/doctools.js"></script>
    <script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <link rel="top" title="Introduction and Motivation" href="index.html" />
    <link rel="prev" title="Introduction and Motivation" href="index.html" />
   
  
  <meta name="viewport" content="width=device-width, initial-scale=0.9, maximum-scale=0.9">

  
       <style type="text/css">
         div.admonition {
           background-color: whiteSmoke;
           border: 1px solid #bababa;
         }
       </style>
      </head>
    
  <body>
    <div class="related">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="genindex.html" title="General Index"
             accesskey="I">index</a></li>
        <li class="right" >
          <a href="index.html" title="Introduction and Motivation"
             accesskey="P">previous</a> |</li>
        <li><a href="index.html">Introduction and Motivation</a> &raquo;</li> 
      </ul>
    </div>  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body">
            
  <div class="section" id="introduction-and-motivation">
<h1>Introduction and Motivation<a class="headerlink" href="#introduction-and-motivation" title="Permalink to this headline">¶</a></h1>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Authors:</th><td class="field-body"><a class="reference external" href="http://computationalphysics.no">Morten Hjorth-Jensen</a>, National Superconducting Cyclotron Laboratory and Department of Physics and Astronomy, Michigan State University, East Lansing, MI 48824, USA &amp; Department of Physics, University of Oslo, Oslo, Norway</td>
</tr>
<tr class="field-even field"><th class="field-name">Date:</th><td class="field-body">July 6-24 2015</td>
</tr>
</tbody>
</table>
<div class="section" id="introduction">
<h2>Introduction<a class="headerlink" href="#introduction" title="Permalink to this headline">¶</a></h2>
<p>To understand why matter is stable, and thereby shed light on the limits of
nuclear stability, is one of the
overarching aims and intellectual challenges
of basic research in nuclear physics. To relate the stability of matter
to the underlying fundamental forces and particles of nature as manifested in nuclear matter, is central
to present and planned rare isotope facilities.
Important properties of nuclear systems which can reveal information about these topics
are for example masses, and thereby binding energies, and density distributions of nuclei.
These are quantities which convey important information on
the shell structure of nuclei, with their
pertinent magic numbers and shell closures or the  eventual disappearence of the latter
away from  the valley of stability.</p>
<p>Neutron-rich nuclei are particularly interesting for the above endeavour. As a particular chain
of isotopes becomes more and more neutron rich, one reaches finally the limit of stability, the so-called
dripline, where one additional neutron makes the next isotopes unstable with respect
to the previous ones. The appearence or not of magic numbers and shell structures,
the formation of neutron skins and halos
can thence be probed via investigations of quantities like  the binding energy
or the charge radii and neutron rms radii of neutron-rich nuclei.
These quantities have in turn important
consequences for theoretical models of nuclear structure and their application in astrophysics.
For example, the neutron radius of <span class="math">\(\,{}^{208}\mbox{Pb}\)</span>, recently extracted from the PREX
experiment at Jefferson Laboratory  can be used to constrain the equation of state of
neutron matter. A related quantity to the
neutron rms radius <span class="math">\(r_n^{\mathrm{rms}}=\langle r^2\rangle_n^{1/2}\)</span> is the neutron skin
<span class="math">\(r_{\mathrm{skin}}=r_n^{\mathrm{rms}}-r_p^{\mathrm{rms}}\)</span>,
where <span class="math">\(r_p^{\mathrm{rms}}\)</span> is the corresponding proton rms radius.
There are several properties which relate the thickness of the neutron skin to quantities in nuclei and
nuclear matter, such as the symmetry energy at the saturation point for nuclear matter, the slope
of the equation of state for neutron matter
or the low-energy electric dipole strength due to the <a class="reference external" href="http://iopscience.iop.org/1402-4896/2013/T152">pigmy dipole resonance</a>.</p>
<p>Having access to precise measurements of masses, radii, and
electromagnetic moments for a wide range of nuclei allows to study
trends with varying neutron excess. A quantitative description of
various experimental data with quantified uncertainty still remains a
major challenge for nuclear structure theory.  Global theoretical
studies of isotopic chains, such as the Ca chain shown in the figure below here, make it possible to test systematic
properties of effective interactions between nucleons. Such calculations also
provide critical tests of limitations of many-body methods. As one
approaches the particle emission thresholds, it becomes increasingly
important to describe correctly the coupling to the continuum of
decays and scattering channels. While the
full treatment of antisymmetrization and short-range correlations has
become routine in first principle  approaches (to be defined later) to nuclear bound states, the
many-body problem becomes more difficult when long-range correlations
and continuum effects are considered.</p>
<div class="figure" id="id1">
<a class="reference internal image-reference" href="_images/careach.png"><img alt="_images/careach.png" src="_images/careach.png" style="width: 500px;" /></a>
<p class="caption"><span class="caption-text">Expected experimental information on the calcium isotopes that can be obtained at FRIB. The limits for detailed spectroscopic information are around <span class="math">\(A\sim 60\)</span></span></p>
</div>
<p>The aim of this first section is to present some of the experimental data which can be used to extract
information about correlations in nuclear systems. In particular, we will start with a theoretical analysis of a quantity called the separation energy for neutrons or protons. This quantity, to be discussed below, is defined as the difference between two binding energies (masses) of neighboring nuclei. As we will see from various figures below and exercises as well, the separation energies display a varying behavior as function of the number of neutrons or protons. These variations from one nucleus to another one, laid the foundation for the introduction of so-called magic numbers and a mean-field picture in order to describe nuclei theoretically.</p>
<p>With a mean- or average-field picture we mean that a given nucleon (either a proton or a neutron) moves in an average potential field which is set up by all other nucleons in the system. Consider for example a nucleus like <span class="math">\(\,{}^{17}\mbox{O}\)</span> with nine neutrons and eight protons. Many properties  of this nucleus can be interpreted in terms of a picture where we can view it as
one neutron on top of <span class="math">\(\,{}^{16}\mbox{O}\)</span>. We infer from data and our theoretical interpretations that this additional neutron behaves almost as an individual neutron which <em>sees</em> an average interaction set up by the remaining 16 nucleons in   <span class="math">\(\,{}^{16}\mbox{O}\)</span>. A nucleus like <span class="math">\(\,{}^{16}\mbox{O}\)</span> is an example of what we in this course will denote as a good closed-shell nucleus. We will come back to what this means later.</p>
<p>Since we want to develop a theory capable of interpreting data in terms of our laws of motion and the pertinent forces,
we can think of this neutron as a particle which moves in a potential field. We can hence attempt at solving our equations of motion (Schroedinger&#8217;s equation in our case) for this system along the same lines as we did in atomic physics when we solved Schroedinger&#8217;s equation for the hydrogen atom. We just need to define a model for our effective single-particle potential.</p>
<p>A simple potential model which enjoys quite some popularity in nuclear physics, is the three-dimensional harmonic oscillator. This potential model captures some of the physics of deeply bound single-particle states but fails in reproducing
the less bound single-particle states. A parametrized, and more realistic,  potential model which is widely used in nuclear physics, is the so-called Woods-Saxon potential. Both the harmonic oscillator and the Woods-Saxon potential models define computational problems that can easily be solved (see below), resulting (with the appropriate parameters) in a rather good reproduction of experiment for nuclei which can be approximated as one nucleon on top (or one nucleon removed) of a so-called closed-shell system.</p>
<p>To be able to interpret a nucleus in such  a way requires at least that we are capable of parametrizing the abovementioned
interactions in order to reproduce say the excitation spectrum of a nucleus like <span class="math">\(\,{}^{17}\mbox{O}\)</span>.</p>
<p>With such a parametrized interaction we are able to solve Schroedinger&#8217;s equation for the motion of one nucleon in a given field. A nucleus is however a true and complicated many-nucleon system, with extremely many degrees of freedom and complicated correlations, rendering the ideal solution of the many-nucleon Schroedinger equation an impossible enterprise. It is much easier to solve a single-particle problem with say a Woods-Saxon potential. Using such a potential hides however many of the complicated correlations and interactions which we see in nuclei. Such an effective single-nucleon potential is for example not capable of
describing properties like the binding energy or the rms radius of a given nucleus.</p>
<p>An improvement to these simpler single-nucleon potentials is given by the Hartree-Fock method, where the variational principle is used to define a mean-field which the nucleons move in. There are many different classes of mean-field methods.
An important difference between these methods and the simpler parametrized mean-field potentials like the harmonic oscillator and the Woods-Saxon potentials, is that the resulting equations contain information about the nuclear forces present in our models for solving Schroedinger&#8217;s equation. Hartree-Fock and other mean-field methods like density functional theory form core topics in later lectures.</p>
<p>The aim of this section is to present some of the experimental data we will confront theory with. In particular, we will focus on separation and shell-gap energies and use these to build a picture of nuclei in terms of (from a philosophical stand we would call this  a reductionist approach) a single-particle picture. The harmonic oscillator will serve as an excellent starting point in building nuclei from the bottom and up. Here we will neglect nuclear forces, these are introduced in the next section when we discuss the Hartree-Fock method.</p>
<p>The aim of this course is to develop our physics intuition of nuclear systems using  a theoretical approach  where we describe data in terms of
the motion of individual nucleons and their mutual interactions.</p>
<p><strong>How our theoretical pictures and models can be used to interpret data is in essence what this course is about</strong>. Our narrative will lead us along a path where we start with single-particle models and end with the theory of the nuclear shell-model. The latter will be used to understand and analyze excitation spectra and decay patterns of nuclei, linking our theoretical understanding with interpretations of experiment. The way we build up our theoretical descriptions and interpretations follows what we may call a standard reductionistic approach, that is we start with what we believe are our effective degrees of freedom (nucleons in our case) and interactions amongst these and solve thereafter the underlying equations of motions. This defines the nuclear many-body problem, and mean-field approaches like Hartree-Fock theory and the nuclear shell-model represent different approaches to our solutions of Schroedinger&#8217;s equation.</p>
<p>We start our tour of experimental data and our interpretations by considering the chain of oxygen isotopes. In the exercises below you will be asked to perform similar analyses for other chains of isotopes.</p>
<p>The oxygen isotopes are the heaviest isotopes for which the drip line is well established.  The drip line is defined as the point where adding one more nucleon leads to an unbound nucleus. Below we will see that we can define the dripline by studying the separation energy. Where the neutron (proton) separation energy changes sign as a function of the number of neutrons (protons) defines the neutron (proton) drip line.</p>
<p>The oxygen isotopes are simple enough to be described by some few selected single-particle degrees of freedom.</p>
<ul class="simple">
<li>Two out of four stable even-even isotopes exhibit a doubly magic nature, namely <span class="math">\(\,{}^{22}\mbox{O}\)</span> (<span class="math">\(Z=8\)</span>, <span class="math">\(N=14\)</span>) and <span class="math">\(\,{}^{24}\mbox{O}\)</span> (<span class="math">\(Z=8\)</span>, <span class="math">\(N=16\)</span>).</li>
<li>The structure of <span class="math">\(\,{}^{22}\mbox{O}\)</span> and <span class="math">\(\,{}^{24}\mbox{O}\)</span> is assumed to be governed by the evolution of the <span class="math">\(1s_{1/2}\)</span> and <span class="math">\(0d_{5/2}\)</span>  one-quasiparticle states.</li>
<li>The isotopes <span class="math">\(\,{}^{25}\mbox{O}\)</span>, <span class="math">\(\,{}^{26}\mbox{O}\)</span>, <span class="math">\(\,{}^{27}\mbox{O}\)</span> and <span class="math">\(\,{}^{28}\mbox{O}\)</span> are outside the drip line, since the <span class="math">\(0d_{3/2}\)</span> orbit is not bound.</li>
</ul>
<blockquote>
<div>Many experiments worldwide!</div></blockquote>
<p>These isotopes have been studied in series of recent experiments. Some of these experiments and theoretical interpretations are discussed in the following articles:</p>
<ul class="simple">
<li><span class="math">\(\,{}^{24}\mbox{O}\)</span> and lighter:  C.&nbsp;R.&nbsp;Hoffman <em>et al.</em>, Phys.&nbsp;Lett.&nbsp;B <strong>672</strong>, 17 (2009); R.&nbsp;Kanungo <em>et al</em>., Phys.&nbsp;Rev.&nbsp;Lett.~**102**, 152501 (2009); C.&nbsp;R.&nbsp;Hoffman <em>et al</em>., Phys.&nbsp;Rev.&nbsp;C <strong>83</strong>, 031303(R) (2011); Stanoiu <em>et al</em>., Phys. Rev. C <strong>69</strong>, 034312 (2004)</li>
<li><span class="math">\(\,{}^{25}\mbox{O}\)</span>: C.&nbsp;R.&nbsp;Hoffman <em>et al</em>., Phys.&nbsp;Rev.&nbsp;Lett. <strong>102</strong>,152501  (2009).</li>
<li><span class="math">\(\,{}^{26}\mbox{O}\)</span>: E.&nbsp;Lunderberg <em>et al</em>., Phys.&nbsp;Rev.&nbsp;Lett. <strong>108</strong>, 142503 (2012).</li>
<li><span class="math">\(\,{}^{26}\mbox{O}\)</span>: Z.&nbsp;Kohley  <em>et al</em>., Study of two-neutron radioactivity in the decay of 26O, Phys.&nbsp;Rev.&nbsp;Lett., <strong>110</strong>, 152501 (2013).</li>
<li>Theory: Oxygen isotopes with three-body forces,  Otsuka <em>et al</em>., Phys.&nbsp;Rev.&nbsp;Lett. <strong>105</strong>, 032501  (2010).  Hagen <em>et al.</em>, Phys.&nbsp;Rev.&nbsp;Lett., <strong>108</strong>, 242501 (2012).</li>
</ul>
</div>
<div class="section" id="masses-and-binding-energies">
<h2>Masses and Binding energies<a class="headerlink" href="#masses-and-binding-energies" title="Permalink to this headline">¶</a></h2>
<p>Our first approach in analyzing data theoretically, is to see if we can use experimental information to</p>
<ul class="simple">
<li>Extract information about a <em>so-called</em> single-particle  behavior</li>
<li>And interpret such a behavior in terms of the underlying forces and microscopic physics</li>
</ul>
<p>The next step is to see if we could use these interpretations to say something about shell closures and magic numbers. Since we focus on single-particle properties, a quantity we can extract from experiment is the separation energy for protons and neutrons. Before we proceed, we need to define quantities like masses and binding energies.   Two excellent reviews on
recent trends in the determination of nuclear masses can be found in the work of <a class="reference external" href="http://journals.aps.org/rmp/abstract/10.1103/RevModPhys.75.1021">Pearson et al.</a> and <a class="reference external" href="http://iopscience.iop.org/1402-4896/2013/T152/014017/">Blaum et al.</a></p>
<p>A basic quantity which can be measured for the ground states of nuclei is the atomic mass <span class="math">\(M(N, Z)\)</span> of the neutral atom with atomic mass number <span class="math">\(A\)</span> and charge <span class="math">\(Z\)</span>. The number of neutrons is <span class="math">\(N\)</span>.</p>
<p>Atomic masses are usually tabulated in terms of the mass excess defined by</p>
<div class="math">
\[\Delta M(N, Z) =  M(N, Z) - uA,\]</div>
<p>where <span class="math">\(u\)</span> is the Atomic Mass Unit</p>
<div class="math">
\[u = M(^{12}\mathrm{C})/12 = 931.49386 \hspace{0.1cm} \mathrm{MeV}/c^2.\]</div>
<p>In this course we will mainly use
data from the 2003 compilation of <a class="reference external" href="http://www.sciencedirect.com/science/journal/03759474/729/1">Audi, Wapstra and Thibault</a>.</p>
<p>The nucleon masses are</p>
<div class="math">
\[m_p = 938.27203(8)\hspace{0.1cm} \mathrm{MeV}/c^2 = 1.00727646688(13)u,\]</div>
<p>and</p>
<div class="math">
\[m_n = 939.56536(8)\hspace{0.1cm} \mathrm{MeV}/c^2 = 1.0086649156(6)u.\]</div>
<p>In the 2003 mass evaluation there are 2127 nuclei measured with an accuracy of 0.2
MeV or better, and 101 nuclei measured with an accuracy of greater than 0.2 MeV. For
heavy nuclei one observes several chains of nuclei with a constant <span class="math">\(N-Z\)</span> value whose masses are obtained from the energy released in <span class="math">\(\alpha\)</span>-decay.</p>
<p>The nuclear binding energy is defined as the energy required to break up a given nucleus
into its constituent parts of <span class="math">\(N\)</span> neutrons and <span class="math">\(Z\)</span> protons. In terms of the atomic masses <span class="math">\(M(N, Z)\)</span> the binding energy is defined by</p>
<div class="math">
\[BE(N, Z) = ZM_H c^2 + Nm_n c^2 - M(N, Z)c^2 ,\]</div>
<p>where <span class="math">\(M_H\)</span> is the mass of the hydrogen atom and <span class="math">\(m_n\)</span> is the mass of the neutron.
In terms of the mass excess the binding energy is given by</p>
<div class="math">
\[BE(N, Z) = Z\Delta_H c^2 + N\Delta_n c^2 -\Delta(N, Z)c^2 ,\]</div>
<p>where <span class="math">\(\Delta_H c^2 = 7.2890\)</span> MeV and <span class="math">\(\Delta_n c^2 = 8.0713\)</span> MeV.</p>
<p>The following python program reads in the experimental data on binding energies and, stored in the file bindingenergies.dat,  plots them as function of the mass number <span class="math">\(A\)</span>. One notices clearly a saturation of the binding energy per nucleon at <span class="math">\(A\approx 56\)</span>.</p>
<div class="highlight-text"><div class="highlight"><pre>import numpy as np
from  matplotlib import pyplot as plt
# Load in data file
data = np.loadtxt(&quot;datafiles/bindingenergies.dat&quot;)
# Make arrays containing x-axis and binding energies as function of A
x = data[:,2]
bexpt = data[:,3]
plt.plot(x, bexpt ,&#39;ro&#39;)
plt.axis([0,270,-1, 10.0])
plt.xlabel(r&#39;$A$&#39;)
plt.ylabel(r&#39;Binding energies in [MeV]&#39;)
plt.legend((&#39;Experiment&#39;), loc=&#39;upper right&#39;)
plt.title(r&#39;Binding energies from experiment&#39;)
plt.savefig(&#39;expbindingenergies.pdf&#39;)
plt.savefig(&#39;expbindingenergies.png&#39;)
plt.show()
</pre></div>
</div>
<p>A popular and physically intuitive model which can be used to parametrize
the experimental binding energies as function of <span class="math">\(A\)</span>, is the so-called
the liquid drop model. The ansatz is based on the following expression</p>
<div class="math">
\[BE(N,Z) = a_1A-a_2A^{2/3}-a_3\frac{Z^2}{A^{1/3}}-a_4\frac{(N-Z)^2}{A},\]</div>
<p>where <span class="math">\(A\)</span> stands for the number of nucleons and the $a_i$s are parameters which are determined by a fit
to the experimental data.</p>
<p>To arrive at the above expression we have assumed that we can make the following assumptions:</p>
<blockquote>
<div><ul class="simple">
<li>There is a volume term <span class="math">\(a_1A\)</span> proportional with the number of nucleons (the energy is also an extensive quantity). When an assembly of nucleons of the same size is packed together into the smallest volume, each interior nucleon has a certain number of other nucleons in contact with it. This contribution is proportional to the volume.</li>
<li>There is a surface energy term <span class="math">\(a_2A^{2/3}\)</span>. The assumption here is that a nucleon at the surface of a nucleus interacts with fewer other nucleons than one in the interior of the nucleus and hence its binding energy is less. This surface energy term takes that into account and is therefore negative and is proportional to the surface area.</li>
<li>There is a Coulomb energy term <span class="math">\(a_3\frac{Z^2}{A^{1/3}}\)</span>. The electric repulsion between each pair of protons in a nucleus yields less binding.</li>
<li>There is an asymmetry term <span class="math">\(a_4\frac{(N-Z)^2}{A}\)</span>. This term is associated with the Pauli exclusion principle and reflectd the fact that the proton-neutron interaction is more attractive on the average than the neutron-neutron and proton-proton interactions.</li>
</ul>
</div></blockquote>
<p>We could also add a so-called pairing term, which is a correction term that
arises from the tendency of proton pairs and neutron pairs to
occur. An even number of particles is more stable than an odd number.
Performing a least-square fit to data, we obtain the following numerical values for the various constants
* <span class="math">\(a_1=15.49\)</span> MeV</p>
<ul class="simple">
<li><span class="math">\(a_2=17.23\)</span> MeV</li>
<li><span class="math">\(a_3=0.697\)</span> MeV</li>
<li><span class="math">\(a_4=22.6\)</span> MeV</li>
</ul>
<p>The python below here allows you to perform a fit of teh above parameters using nonlinear least squares curvefitting.</p>
<p>The following python program reads now in the experimental data on binding energies as well as the results from the above liquid drop model and plots these energies as function of the mass number <span class="math">\(A\)</span>. One sees that for larger values of <span class="math">\(A\)</span>, there is a better agreement with data.</p>
<div class="highlight-text"><div class="highlight"><pre>import numpy as np
from  matplotlib import pyplot as plt
# Load in data file
data = np.loadtxt(&quot;datafiles/bindingenergies.dat&quot;)
# Make arrays containing x-axis and binding energies as function of
x = data[:,2]
bexpt = data[:,3]
liquiddrop = data[:,4]
plt.plot(x, bexpt ,&#39;b-o&#39;, x, liquiddrop, &#39;r-o&#39;)
plt.axis([0,270,-1, 10.0])
plt.xlabel(r&#39;$A$&#39;)
plt.ylabel(r&#39;Binding energies in [MeV]&#39;)
plt.legend((&#39;Experiment&#39;,&#39;Liquid Drop&#39;), loc=&#39;upper right&#39;)
plt.title(r&#39;Binding energies from experiment and liquid drop&#39;)
plt.savefig(&#39;bindingenergies.pdf&#39;)
plt.savefig(&#39;bindingenergies.png&#39;)
plt.show()
</pre></div>
</div>
<p>This  python program reads now in the experimental data on binding energies and performs a nonlinear least square fitting of the data. In the example here we use only the parameters <span class="math">\(a_1\)</span> and <span class="math">\(a_2\)</span>, leaving it as an exercise to the reader to perform the fit for all four paramters. The results are plotted and compared with the experimental values.  To read more about non-linear least square methods, see for example the text of M.J. Box, D. Davies and W.H. Swann, Non-Linear optimisation Techniques, Oliver &amp; Boyd, 1969.</p>
<div class="highlight-text"><div class="highlight"><pre>import numpy as np
from scipy.optimize import curve_fit
from  matplotlib import pyplot as plt
# Load in data file
data = np.loadtxt(&quot;datafiles/bindingenergies.dat&quot;)
# Make arrays containing A on x-axis and binding energies
A = data[:,2]
bexpt = data[:,3]
# The function we want to fit to, only two terms here
def func(A,a1, a2):
    return a1*A-a2*(A**(2.0/3.0))
# function to perform nonlinear least square with guess for a1 and a2
popt, pcov = curve_fit(func, A, bexpt, p0 = (16.0, 18.0))
a1  = popt[0]
a2 = popt[1]
liquiddrop = a1*A-a2*(A**(2.0/3.0))

plt.plot(A, bexpt ,&#39;bo&#39;, A, liquiddrop, &#39;ro&#39;)
plt.axis([0,270,-1, 10.0])
plt.xlabel(r&#39;$A$&#39;)
plt.ylabel(r&#39;Binding energies in [MeV]&#39;)
plt.legend((&#39;Experiment&#39;,&#39;Liquid Drop&#39;), loc=&#39;upper right&#39;)
plt.title(r&#39;Binding energies from experiment and liquid drop&#39;)
plt.savefig(&#39;bindingenergies.pdf&#39;)
plt.savefig(&#39;bindingenergies.png&#39;)
plt.show()
</pre></div>
</div>
<p>We are now interested in interpreting experimental binding energies  in terms of a single-particle picture.
In order to do so, we  consider first energy conservation for nuclear transformations that include, for
example, the fusion of two nuclei <span class="math">\(a\)</span> and <span class="math">\(b\)</span> into the combined system <span class="math">\(c\)</span></p>
<div class="math">
\[{^{N_a+Z_a}}a+ {^{N_b+Z_b}}b\rightarrow {^{N_c+Z_c}}c\]</div>
<p>or the decay of nucleus <span class="math">\(c\)</span> into two other nuclei <span class="math">\(a\)</span> and <span class="math">\(b\)</span></p>
<div class="math">
\[^{N_c+Z_c}c \rightarrow  ^{N_a+Z_a}a+ ^{N_b+Z_b}b\]</div>
<p>In general we have the reactions</p>
<div class="math">
\[\sum_i {^{N_i+Z_i}}i \rightarrow  \sum_f {^{N_f+Z_f}}f\]</div>
<p>We require also that the number of protons and neutrons (the total number of nucleons) is conserved in the initial stage and final stage, unless we have processes which violate baryon conservation,</p>
<div class="math">
\[\sum_iN_i = \sum_f N_f \hspace{0.2cm}\mathrm{and} \hspace{0.2cm}\sum_iZ_i = \sum_f Z_f.\]</div>
</div>
<div class="section" id="values-and-separation-energies">
<h2><span class="math">\(Q\)</span>-values and separation energies<a class="headerlink" href="#values-and-separation-energies" title="Permalink to this headline">¶</a></h2>
<p>The above processes can be characterized by an energy difference called the <span class="math">\(Q\)</span> value, defined as</p>
<div class="math">
\[Q=\sum_i M(N_i, Z_i)c^2-\sum_f M(N_f, Z_f)c^2=\sum_i BE(N_f, Z_f)-\sum_i BE(N_i, Z_i)\]</div>
<p>Spontaneous decay involves a single initial nuclear state and is allowed if <span class="math">\(Q &gt; 0\)</span>. In the decay, energy is released in the form of the kinetic energy of the final products. Reactions involving two initial nuclei are called endothermic (a net loss of energy) if <span class="math">\(Q &lt; 0\)</span>. The reactions are exothermic (a net release of energy) if <span class="math">\(Q &gt; 0\)</span>.</p>
<p>Let us study the Q values associated with the removal of one or two nucleons from
a nucleus. These are conventionally defined in terms of the one-nucleon and two-nucleon
separation energies. The neutron separation energy is defined as</p>
<div class="math">
\[S_n= -Q_n= BE(N,Z)-BE(N-1,Z),\]</div>
<p>and the proton separation energy reads</p>
<div class="math">
\[S_p= -Q_p= BE(N,Z)-BE(N,Z-1).\]</div>
<p>The two-neutron separation energy is defined as</p>
<div class="math">
\[S_{2n}= -Q_{2n}= BE(N,Z)-BE(N-2,Z),\]</div>
<p>and  the two-proton separation energy is given by</p>
<div class="math">
\[S_{2p}= -Q_{2p}= BE(N,Z)-BE(N,Z-2),\]</div>
<p>Using say the neutron separation energies (alternatively the proton separation energies)</p>
<div class="math">
\[S_n= -Q_n= BE(N,Z)-BE(N-1,Z),\]</div>
<p>we can define the so-called energy gap for neutrons (or protons) as</p>
<div class="math">
\[\Delta S_n= BE(N,Z)-BE(N-1,Z)-\left(BE(N+1,Z)-BE(N,Z)\right),\]</div>
<p>or</p>
<div class="math">
\[\Delta S_n= 2BE(N,Z)-BE(N-1,Z)-BE(N+1,Z).\]</div>
<p>This quantity can in turn be used to determine which nuclei are magic or not.
For protons we would have</p>
<div class="math">
\[\Delta S_p= 2BE(N,Z)-BE(N,Z-1)-BE(N,Z+1).\]</div>
<p>We leave it as an exercise to the reader to define and interpret the two-neutron or two-proton gaps.</p>
<p>The following python programs can now be used to plot the separation energies and the energy gaps for the oxygen isotopes.  The following python code reads the separation energies from file for all oxygen isotopes from <span class="math">\(A=13\)</span> to <span class="math">\(A=25\)</span>, The data are taken from the file <em>snox.dat</em>.  This files contains the separation energies and the shell gap energies.</p>
<div class="highlight-text"><div class="highlight"><pre>import numpy as np
from  matplotlib import pyplot as plt
# Load in data file
data = np.loadtxt(&quot;datafiles/snox.dat&quot;)
# Make arrays containing x-axis and binding energies as function of
x = data[:,1]
y = data[:,2]

plt.plot(x, y,&#39;b-+&#39;,markersize=6)
plt.axis([4,18,-1, 25.0])
plt.xlabel(r&#39;Number of neutrons $N$&#39;,fontsize=20)
plt.ylabel(r&#39;$S_n$ [MeV]&#39;,fontsize=20)
plt.legend((&#39;Separation energies for oxygen isotpes&#39;), loc=&#39;upper right&#39;)
plt.title(r&#39;Separation energy for the oxygen isotopes&#39;)
plt.savefig(&#39;snoxygen.pdf&#39;)
plt.savefig(&#39;snoxygen.png&#39;)
plt.show()
</pre></div>
</div>
<p>Here we display the python program for plotting the corresponding results for shell gaps for the oyxgen isotopes.</p>
<div class="highlight-text"><div class="highlight"><pre>import numpy as np
from  matplotlib import pyplot as plt
# Load in data file
data = np.loadtxt(&quot;datafiles/snox.dat&quot;)
# Make arrays containing x-axis and binding energies as function of
x = data[:,1]
y = data[:,3]

plt.plot(x, y,&#39;b-+&#39;,markersize=6)
plt.axis([4,18,-7, 12.0])
plt.xlabel(r&#39;Number of neutrons $N$&#39;,fontsize=20)
plt.ylabel(r&#39;$\Delta S_n$ [MeV]&#39;,fontsize=20)
plt.legend((&#39;Shell gap energies for oxygen isotpes&#39;), loc=&#39;upper right&#39;)
plt.title(r&#39;Shell gap energies for the oxygen isotopes&#39;)
plt.savefig(&#39;gapoxygen.pdf&#39;)
plt.savefig(&#39;gapoxygen.png&#39;)
plt.show()
</pre></div>
</div>
<p>Since we will focus in the beginning on single-particle degrees of freedom and mean-field approaches before we
start with nuclear forces and many-body approaches like the nuclear shell-model, there are some features to be noted</p>
<ul class="simple">
<li>In the discussion of the liquid drop model and binding energies, we note that the total binding energy is not that different from the sum of the individual neutron and proton masses.</li>
</ul>
<p>One may thus infer that intrinsic properties of nucleons in a nucleus are close to those of free nucleons.
* In the discussion of the neutron separation energies for the oxygen isotopes, we note  a clear staggering effect between odd and even isotopes with the even ones being more bound (larger separation energies). We will later link this to strong pairing correlations in nuclei.</p>
<ul class="simple">
<li>The neutron separation energy becomes negative at <span class="math">\(\,{}^{25}\mbox{O}\)</span>, making this nucleus unstable with respect to the emission of one neutron. A nucleus like <span class="math">\(\,{}^{24}\mbox{O}\)</span> is thus the last stable oxygen isotopes which has been observed. &#8220;Oxygen-26&#8221;:&#8221;ournals.aps.org/prl/abstract/10.1103/PhysRevLett.108.142503&#8221; . has been found to be unbound with respect to <span class="math">\(\,{}^{24}\mbox{O}\)</span>.</li>
<li>We note also that there are large shell-gaps for some nuclei, meaning that more energy is needed to remove one nucleon. These gaps are used to define so-called magic numbers. For the oxygen isotopes we see a clear gap for <span class="math">\(\,{}^{16}\mbox{O}\)</span>. We will interpret this gap as one of several experimental properties that define so-called magic numbers. In our discussion below we will make a first interpretation using  single-particle states from the harmonic oscillator and the Woods-Saxon potential.</li>
</ul>
<p>In the exercises below you will be asked to perform a similar analysis for other chains of isotopes and interpret the results.</p>
</div>
<div class="section" id="radii">
<h2>Radii<a class="headerlink" href="#radii" title="Permalink to this headline">¶</a></h2>
<p>The root-mean-square (rms) charge radius has been measured for the ground states of many
nuclei. For a spherical charge density, <span class="math">\(\rho(\boldsymbol{r})\)</span>, the mean-square radius is defined by</p>
<div class="math">
\[\langle r^2\rangle = \frac{ \int  d \boldsymbol{r} \rho(\boldsymbol{r}) r^2}{ \int  d \boldsymbol{r} \rho(\boldsymbol{r})},\]</div>
<p>and the rms radius is the square root of this quantity denoted by</p>
<div class="math">
\[R =\sqrt{ \langle r^2\rangle}.\]</div>
<p>Radii for most stable
nuclei have been deduced from electron scattering form
factors and/or from the x-ray transition energies of muonic atoms.
The relative radii for a
series of isotopes can be extracted from the isotope shifts of atomic x-ray transitions.
The rms radius for the nuclear point-proton density, <span class="math">\(R_p\)</span> is obtained from the rms charge radius by:</p>
<div class="math">
\[R_p = \sqrt{R^2_{\mathrm{ch}}- R^2_{\mathrm{corr}}},\]</div>
<p>where</p>
<div class="math">
\[R^2_{\mathrm{corr}}= R^2_{\mathrm{op}}+(N/Z)R^2_{\mathrm{on}}+R^2_{\mathrm{rel}},\]</div>
<p>where</p>
<div class="math">
\[R_{\mathrm{op}}= 0.875(7) \mathrm{fm}.\]</div>
<p>is the rms radius of the proton, <span class="math">\(R^2_{\mathrm{on}} = 0.116(2)\)</span> $mbox{fm}^{2}$ is the
mean-square radius of the neutron and <span class="math">\(R^2_{\mathrm{rel}} = 0.033\)</span> $mbox{fm}^{2}$ is the relativistic Darwin-Foldy correction. There are also smaller nucleus-dependent relativistic spin-orbit and
mesonic-exchange corrections that should be included.</p>
</div>
<div class="section" id="definitions">
<h2>Definitions<a class="headerlink" href="#definitions" title="Permalink to this headline">¶</a></h2>
<p>We will now introduce the potential models we have discussex above, namely the harmonic oscillator and the Woods-Saxon potentials.  In order to proceed, we need some definitions.</p>
<p>We define an operator as <span class="math">\(\hat{O}\)</span> throughout. Unless otherwise specified the total number of nucleons is
always <span class="math">\(A\)</span> and <span class="math">\(d\)</span> is the dimension of the system.  In nuclear physics
we normally define the total number of particles to be <span class="math">\(A=N+Z\)</span>, where
<span class="math">\(N\)</span> is total number of neutrons and <span class="math">\(Z\)</span> the total number of
protons. In case of other baryons such as isobars <span class="math">\(\Delta\)</span> or various
hyperons such as <span class="math">\(\Lambda\)</span> or <span class="math">\(\Sigma\)</span>, one needs to add their
definitions.  When we refer to a single neutron we will use the label <span class="math">\(n\)</span> and when we refer to a single proton we will use the label <span class="math">\(p\)</span>. Unless otherwise specified, we will simply call these particles for nucleons.</p>
<p>The quantum numbers of a single-particle state in coordinate space are
defined by the variables</p>
<div class="math">
\[x=(\boldsymbol{r},\sigma),\]</div>
<p>where</p>
<div class="math">
\[\boldsymbol{r}\in {\mathbb{R}}^{d},\]</div>
<p>with <span class="math">\(d=1,2,3\)</span> represents the spatial coordinates and <span class="math">\(\sigma\)</span> is the eigenspin of the particle. For fermions with eigenspin <span class="math">\(1/2\)</span> this means that</p>
<div class="math">
\[x\in {\mathbb{R}}^{d}\oplus (\frac{1}{2}),\]</div>
<p>and the integral</p>
<div class="math">
\[\int dx = \sum_{\sigma}\int d^dr = \sum_{\sigma}\int d\boldsymbol{r},\]</div>
<p>and</p>
<div class="math">
\[\int d^Ax= \int dx_1\int dx_2\dots\int dx_A.\]</div>
<p>Since we are dealing with protons and neutrons we need to add isospin as a new degree of freedom.</p>
<p>Including isospin <span class="math">\(\tau\)</span> we have</p>
<div class="math">
\[x=(\boldsymbol{r},\sigma,\tau),\]</div>
<p>where</p>
<div class="math">
\[\boldsymbol{r}\in {\mathbb{R}}^{3},\]</div>
<p>For nucleons, which are fermions with eigenspin <span class="math">\(1/2\)</span> and isospin <span class="math">\(1/2\)</span> this means that</p>
<div class="math">
\[x\in {\mathbb{R}}^{d}\oplus (\frac{1}{2})\oplus (\frac{1}{2}),\]</div>
<p>and the integral</p>
<div class="math">
\[\int dx = \sum_{\sigma\tau}\int d\boldsymbol{r},\]</div>
<p>and</p>
<div class="math">
\[\int d^Ax= \int dx_1\int dx_2\dots\int dx_A.\]</div>
<p>We will use the standard nuclear physics definition of isospin, resulting in <span class="math">\(\tau_z=-1/2\)</span> for protons and <span class="math">\(\tau_z=1/2\)</span> for neutrons.</p>
<p>The quantum mechanical wave function of a given state with quantum numbers <span class="math">\(\lambda\)</span> (encompassing all quantum numbers needed to specify the system), ignoring time, is</p>
<div class="math">
\[\Psi_{\lambda}=\Psi_{\lambda}(x_1,x_2,\dots,x_A),\]</div>
<p>with <span class="math">\(x_i=(\boldsymbol{r}_i,\sigma_i,\tau_i)\)</span> and the projections of <span class="math">\(\sigma_i\)</span> and <span class="math">\(\tau_i\)</span> take the values
<span class="math">\(\{-1/2,+1/2\}\)</span>.
We will hereafter always refer to <span class="math">\(\Psi_{\lambda}\)</span> as the exact wave function, and if the ground state is not degenerate we label it as</p>
<div class="math">
\[\Psi_0=\Psi_0(x_1,x_2,\dots,x_A).\]</div>
<p>Since the solution <span class="math">\(\Psi_{\lambda}\)</span> seldomly can be found in closed form, approximations are sought. In this text we define an approximative wave function or an ansatz to the exact wave function as</p>
<div class="math">
\[\Phi_{\lambda}=\Phi_{\lambda}(x_1,x_2,\dots,x_A),\]</div>
<p>with</p>
<div class="math">
\[\Phi_{0}=\Phi_{0}(x_{1},x_{2},\dots,x_{A}),\]</div>
<p>being the ansatz for the ground state.</p>
<p>The wave function <span class="math">\(\Psi_{\lambda}\)</span> is sought in the Hilbert space of either symmetric or anti-symmetric <span class="math">\(N\)</span>-body functions, namely</p>
<div class="math">
\[\Psi_{\lambda}\in {\cal H}_A:= {\cal H}_1\oplus{\cal H}_1\oplus\dots\oplus{\cal H}_1,\]</div>
<p>where the single-particle Hilbert space <span class="math">\(\hat{H}_1\)</span> is the space of square integrable functions over <span class="math">\(\in {\mathbb{R}}^{d}\oplus (\sigma)\oplus (\tau)\)</span> resulting in</p>
<div class="math">
\[{\cal H}_1:= L^2(\mathbb{R}^{d}\oplus (\sigma)\oplus (\tau)).\]</div>
<p>Our Hamiltonian is invariant under the permutation (interchange) of two particles.
Since we deal with fermions however, the total wave function is antisymmetric.
Let <span class="math">\(\hat{P}\)</span> be an operator which interchanges two particles.
Due to the symmetries we have ascribed to our Hamiltonian, this operator commutes with the total Hamiltonian,</p>
<div class="math">
\[[\hat{H},\hat{P}] = 0,\]</div>
<p>meaning that <span class="math">\(\Psi_{\lambda}(x_1, x_2, \dots , x_A)\)</span> is an eigenfunction of
<span class="math">\(\hat{P}\)</span> as well, that is</p>
<div class="math">
\[\hat{P}_{ij}\Psi_{\lambda}(x_1, x_2, \dots,x_i,\dots,x_j,\dots,x_A)=
\beta\Psi_{\lambda}(x_1, x_2, \dots,x_j,\dots,x_i,\dots,x_A),\]</div>
<p>where <span class="math">\(\beta\)</span> is the eigenvalue of <span class="math">\(\hat{P}\)</span>. We have introduced the suffix <span class="math">\(ij\)</span> in order to indicate that we permute particles <span class="math">\(i\)</span> and <span class="math">\(j\)</span>.
The Pauli principle tells us that the total wave function for a system of fermions
has to be antisymmetric, resulting in the eigenvalue <span class="math">\(\beta = -1\)</span>.</p>
<p>The Schrodinger equation reads</p>
<div class="math" id="equation-eq:basicSE1">
<span class="eqno">(1)</span>\[     \hat{H}(x_1, x_2, \dots , x_A) \Psi_{\lambda}(x_1, x_2, \dots , x_A) =
     E_\lambda  \Psi_\lambda(x_1, x_2, \dots , x_A),\]</div>
<p>where the vector <span class="math">\(x_i\)</span> represents the coordinates (spatial, spin and isospin) of particle <span class="math">\(i\)</span>, <span class="math">\(\lambda\)</span> stands  for all the quantum
numbers needed to classify a given <span class="math">\(A\)</span>-particle state and <span class="math">\(\Psi_{\lambda}\)</span> is the pertaining eigenfunction.  Throughout this course,
<span class="math">\(\Psi\)</span> refers to the exact eigenfunction, unless otherwise stated.</p>
<p>We write the Hamilton operator, or Hamiltonian,  in a generic way</p>
<div class="math">
\[\hat{H} = \hat{T} + \hat{V}\]</div>
<p>where <span class="math">\(\hat{T}\)</span>  represents the kinetic energy of the system</p>
<div class="math">
\[\hat{T} = \sum_{i=1}^A \frac{\mathbf{p}_i^2}{2m_i} = \sum_{i=1}^A \left( -\frac{\hbar^2}{2m_i} \mathbf{\nabla_i}^2 \right) =
        \sum_{i=1}^A t(x_i)\]</div>
<p>while the operator <span class="math">\(\hat{V}\)</span> for the potential energy is given by</p>
<div class="math" id="equation-eq:firstv">
<span class="eqno">(2)</span>\[             \hat{V} = \sum_{i=1}^A \hat{u}_{\mathrm{ext}}(x_i) + \sum_{ji=1}^A v(x_i,x_j)+\sum_{ijk=1}^Av(x_i,x_j,x_k)+\dots\]</div>
<p>Hereafter we use natural units, viz.&nbsp;<span class="math">\(\hbar=c=e=1\)</span>, with <span class="math">\(e\)</span> the elementary charge and <span class="math">\(c\)</span> the speed of light. This means that momenta and masses
have dimension energy.</p>
<p>The potential energy part includes also an external potential <span class="math">\(\hat{u}_{\mathrm{ext}}(x_i)\)</span>.</p>
<p>In a non-relativistic approach to atomic  physics, this external potential is given by the attraction an electron feels from the atomic nucleus. The latter being much heavier than the involved electrons, is often used to define a natural center of mass. In nuclear physics there is no such external potential. It is the nuclear force which results in binding in nuclear systems. In a non-relativistic framework, the nuclear force contains two-body, three-body and more complicated degrees of freedom. The potential energy reads then</p>
<div class="math">
\[\hat{V} = \sum_{ij}^A v(x_i,x_j)+\sum_{ijk}^Av(x_i,x_j,x_k)+\dots\]</div>
<p>Three-body and more  complicated forces arise since we are dealing with protons and neutrons as effective degrees of freedom. We will come back to this topic later. Furthermore, in large parts of these lectures we will assume that the potential energy can be approximated by a two-body interaction only. Our Hamiltonian reads then</p>
<div class="math" id="equation-eq:firstH">
<span class="eqno">(3)</span>\[             \hat{H} = \sum_{i=1}^A \frac{\mathbf{p}_i^2}{2m_i}+\sum_{ij}^A v(x_i,x_j).\]</div>
</div>
<div class="section" id="a-modified-hamiltonian">
<h2>A modified Hamiltonian<a class="headerlink" href="#a-modified-hamiltonian" title="Permalink to this headline">¶</a></h2>
<p>It is however, from a computational point of view, convenient to introduce an external potential <span class="math">\(\hat{u}_{\mathrm{ext}}(x_i)\)</span> by adding and substracting it to the original Hamiltonian.
This means that our Hamiltonian can be rewritten as</p>
<div class="math">
\[\begin{split}\hat{H} = \hat{H}_0 + \hat{H}_I
= \sum_{i=1}^A \hat{h}_0(x_i) + \sum_{i &lt; j=1}^A \hat{v}(x_{ij})-\sum_{i=1}^A\hat{u}_{\mathrm{ext}}(x_i),\end{split}\]</div>
<p>with</p>
<div class="math">
\[\hat{H}_0=\sum_{i=1}^A \hat{h}_0(x_i) =  \sum_{i=1}^A\left(\hat{t}(x_i) + \hat{u}_{\mathrm{ext}}(x_i)\right).\]</div>
<p>The interaction (or potential energy term) reads now</p>
<div class="math">
\[\begin{split}\hat{H}_I=  \sum_{i &lt; j=1}^A \hat{v}(x_{ij})-\sum_{i=1}^A\hat{u}_{\mathrm{ext}}(x_i).\end{split}\]</div>
<p>In nuclear physics the one-body part <span class="math">\(u_{\mathrm{ext}}(x_i)\)</span> is often approximated by a harmonic oscillator potential or a
Woods-Saxon potential. However, this is not fully correct, because as we have discussed, nuclei are self-bound systems and there is no external confining potential. As we will see later, <em>the  \( hat{H}_0 \)  part of the hamiltonian cannot be used to compute the binding energy of a nucleus since it is not based on a model for the nuclear forces</em>. That is, the binding energy is not the sum of the individual single-particle energies.</p>
<p>Why do we introduce the  Hamiltonian  in the form</p>
<div class="math">
\[\hat{H} = \hat{H}_0 + \hat{H}_I?\]</div>
<p>There are many reasons for this. Let us look at some of them, using the harmonic oscillator in three dimensions as our starting point. For the harmonic oscillator we know that</p>
<div class="math">
\[\hat{h}_0(x_i)\psi_{\alpha}(x_i)=\varepsilon_{\alpha}\psi_{\alpha}(x_i),\]</div>
<p>where the eigenvalues are <span class="math">\(\varepsilon_{\alpha}\)</span> and the eigenfunctions are <span class="math">\(\psi_{\alpha}(x_i)\)</span>. The subscript <span class="math">\(\alpha\)</span> represents quantum numbers like the orbital angular momentum <span class="math">\(l_{\alpha}\)</span>, its projection <span class="math">\(m_{l_{\alpha}}\)</span> and the
principal quantum number <span class="math">\(n_{\alpha}=0,1,2,\dots\)</span>.</p>
<p>The eigenvalues are</p>
<div class="math">
\[\varepsilon_{\alpha} = \hbar\omega \left(2n_{\alpha}+l_{\alpha}+\frac{3}{2}\right).\]</div>
<dl class="docutils">
<dt>The following mathematical properties of the  harmonic oscillator are handy.</dt>
<dd><ul class="first last simple">
<li>First of all we have a complete basis of orthogonal eigenvectors. These have well-know expressions and can be easily be encoded.</li>
<li>With a complete basis <span class="math">\(\psi_{\alpha}(x_i)\)</span>, we can construct a new basis <span class="math">\(\phi_{\tau}(x_i)\)</span> by expanding in terms of a harmonic oscillator basis, that is</li>
</ul>
</dd>
</dl>
<div class="math">
\[\phi_{\tau}(x_i)=\sum_{\alpha} C_{\tau\alpha}\psi_{\alpha}(x_i),\]</div>
<dl class="docutils">
<dt>where <span class="math">\(C_{\tau\alpha}\)</span> represents the overlap between the two basis sets.</dt>
<dd><ul class="first last simple">
<li>As we will see later, the harmonic oscillator basis allows us to compute in an expedient way matrix elements of the interactions between two nucleons.  Using the above expansion we can in turn represent nuclear forces in terms of new basis, for example the  Woods-Saxon basis  to be discussed later here.</li>
</ul>
</dd>
</dl>
<p>The harmonic oscillator (a shifted one by a negative constant) provides also a very good approximation to most bound single-particle states. Furthermore, it serves as a starting point in building up our picture of nuclei, in particular how we define magic numbers and systems with one nucleon added to (or removed from) a closed-shell core nucleus. The figure here shows
the various harmonic oscillator states, with those obtained with a Woods-Saxon potential as well, including a spin-orbit splitting (to be discussed below).</p>
<div class="figure" id="id2">
<a class="reference internal image-reference" href="_images/singleparticle.png"><img alt="_images/singleparticle.png" src="_images/singleparticle.png" style="width: 500px;" /></a>
<p class="caption"><span class="caption-text">Single-particle spectrum and quantum numbers for a harmonic oscillator potential and a Woods-Saxon potential with and without a spin-orbit force</span></p>
</div>
<p>In nuclear physics the one-body part <span class="math">\(u_{\mathrm{ext}}(x_i)\)</span> is often
approximated by a harmonic oscillator potential. However,  as we also noted with the Woods-Saxon potential there is no
external confining potential in nuclei.</p>
<p>What many people do then, is to add and subtract a harmonic oscillator potential,
with</p>
<div class="math">
\[\hat{u}_{\mathrm{ext}}(x_i)=\hat{u}_{\mathrm{ho}}(x_i)= \frac{1}{2}m\omega^2 r_i^2,\]</div>
<p>where <span class="math">\(\omega\)</span> is the oscillator frequency. This leads to</p>
<div class="math">
\[\begin{split}\hat{H} = \hat{H_0} + \hat{H_I}
= \sum_{i=1}^A \hat{h}_0(x_i) + \sum_{i &lt; j=1}^A \hat{v}(x_{ij})-\sum_{i=1}^A\hat{u}_{\mathrm{ho}}(x_i),\end{split}\]</div>
<p>with</p>
<div class="math">
\[H_0=\sum_{i=1}^A \hat{h}_0(x_i) =  \sum_{i=1}^A\left(\hat{t}(x_i) + \hat{u}_{\mathrm{ho}}(x_i)\right).\]</div>
<p>Many practitioners use this as the standard Hamiltonian when doing nuclear structure calculations.
This is ok if the number of nucleons is large, but still with this Hamiltonian, we do not obey translational invariance.  How can we cure this?</p>
<blockquote>
<div>In setting up a translationally invariant Hamiltonian
the following expressions are helpful.
The center-of-mass (CoM)  momentum is</div></blockquote>
<div class="math">
\[           P=\sum_{i=1}^A\boldsymbol{p}_i,\]\[
and we have that\]</div>
<div class="math">
\[\begin{split}        \sum_{i=1}^A\boldsymbol{p}_i^2 =
        \frac{1}{A}\left[\boldsymbol{P}^2+\sum_{i &lt; j}(\boldsymbol{p}_i-\boldsymbol{p}_j)^2\right]\end{split}\]\[
meaning that\]</div>
<div class="math">
\[\begin{split}        \left[\sum_{i=1}^A\frac{\boldsymbol{p}_i^2}{2m} -\frac{\boldsymbol{P}^2}{2mA}\right]
        =\frac{1}{2mA}\sum_{i &lt; j}(\boldsymbol{p}_i-\boldsymbol{p}_j)^2.\end{split}\]\[
In a similar fashion we can define the CoM coordinate\]</div>
<div class="math">
\[            \boldsymbol{R}=\frac{1}{A}\sum_{i=1}^{A}\boldsymbol{r}_i,\]\[
which yields\]</div>
<div class="math">
\[\begin{split}        \sum_{i=1}^A\boldsymbol{r}_i^2 =
        \frac{1}{A}\left[A^2\boldsymbol{R}^2+\sum_{i &lt; j}(\boldsymbol{r}_i-\boldsymbol{r}_j)^2\right].\end{split}\]\[
If we then introduce the harmonic oscillator one-body Hamiltonian\]</div>
<div class="math">
\[             H_0= \sum_{i=1}^A\left(\frac{\boldsymbol{p}_i^2}{2m}+
                  \frac{1}{2}m\omega^2\boldsymbol{r}_i^2\right),\]\[
with  \( \omega \)  the oscillator frequency,
we can rewrite the latter as\]</div>
<div class="math" id="equation-eq:obho">
<span class="eqno">(4)</span>\[\begin{split}           H_{\mathrm{HO}}= \frac{\boldsymbol{P}^2}{2mA}+\frac{mA\omega^2\boldsymbol{R}^2}{2}
                 +\frac{1}{2mA}\sum_{i &lt; j}(\boldsymbol{p}_i-\boldsymbol{p}_j)^2
                 +\frac{m\omega^2}{2A}\sum_{i &lt; j}(\boldsymbol{r}_i-\boldsymbol{r}_j)^2.\end{split}\]</div>
<p>Alternatively, we could write it as</p>
<div class="math">
\[\begin{split}H_{\mathrm{HO}}= H_{\mathrm{CoM}}+\frac{1}{2mA}\sum_{i &lt; j}(\boldsymbol{p}_i-\boldsymbol{p}_j)^2
           +\frac{m\omega^2}{2A}\sum_{i &lt; j}(\boldsymbol{r}_i-\boldsymbol{r}_j)^2,\end{split}\]</div>
<p>The center-of-mass term is defined as</p>
<div class="math">
\[             H_{\mathrm{CoM}}= \frac{\boldsymbol{P}^2}{2mA}+\frac{mA\omega^2\boldsymbol{R}^2}{2}.\]\[
The translationally invariant one- and two-body  Hamiltonian reads for an A-nucleon system,\]</div>
<div class="math">
\[:label: eq:ham\]\[\begin{split}       \hat{H}=\left[\sum_{i=1}^A\frac{\boldsymbol{p}_i^2}{2m} -\frac{\boldsymbol{P}^2}{2mA}\right] +\sum_{i &lt; j}^A V_{ij} \; ,\end{split}\]\[
where  \( V_{ij} \)  is the nucleon-nucleon interaction. Adding zero as here\]</div>
<div class="math">
\[\begin{split}\sum_{i=1}^A\frac{1}{2}m\omega^2\boldsymbol{r}_i^2-
\frac{m\omega^2}{2A}\left[\boldsymbol{R}^2+\sum_{i &lt; j}(\boldsymbol{r}_i-\boldsymbol{r}_j)^2\right]=0.\end{split}\]</div>
<p>we can then rewrite the Hamiltonian as</p>
<div class="math">
\[\begin{split}\hat{H}=\sum_{i=1}^A \left[ \frac{\boldsymbol{p}_i^2}{2m}
+\frac{1}{2}m\omega^2 \boldsymbol{r}^2_i
\right] + \sum_{i &lt; j}^A \left[ V_{ij}-\frac{m\omega^2}{2A}
(\boldsymbol{r}_i-\boldsymbol{r}_j)^2
\right]-H_{\mathrm{CoM}}.\end{split}\]</div>
<p>The Woods-Saxon potential is a mean field potential for the nucleons (protons and neutrons)
inside an atomic nucleus. It represent an average potential that a given nucleon feels from  the forces applied on each nucleon.
The parametrization is</p>
<div class="math">
\[\hat{u}_{\mathrm{ext}}(r)=-\frac{V_0}{1+\exp{(r-R)/a}},\]</div>
<p>with <span class="math">\(V_0\approx 50\)</span> MeV representing the potential well depth, <span class="math">\(a\approx 0.5\)</span> fm
length representing the &#8220;surface thickness&#8221; of the nucleus and <span class="math">\(R=r_0A^{1/3}\)</span>, with <span class="math">\(r_0=1.25\)</span> fm and <span class="math">\(A\)</span> the number of nucleons.
The value for <span class="math">\(r_0\)</span> can be extracted from a fit to data, see for example <a class="reference external" href="http://www.sciencedirect.com/science/article/pii/S037594740600769X">M. |nbsp| Kirson</a>.</p>
<p>The following python code produces a plot of the Woods-Saxon potential with the above parameters.</p>
<div class="highlight-text"><div class="highlight"><pre>import numpy as np
from  matplotlib import pyplot as plt
from matplotlib import rc, rcParams
import matplotlib.units as units
import matplotlib.ticker as ticker
rc(&#39;text&#39;,usetex=True)
rc(&#39;font&#39;,**{&#39;family&#39;:&#39;serif&#39;,&#39;serif&#39;:[&#39;Woods-Saxon potential&#39;]})
font = {&#39;family&#39; : &#39;serif&#39;,
        &#39;color&#39;  : &#39;darkred&#39;,
        &#39;weight&#39; : &#39;normal&#39;,
        &#39;size&#39;   : 16,
        }
v0 = 50
A = 100
a = 0.5
r0 = 1.25
R = r0*A**(0.3333)
x = np.linspace(0.0, 10.0)
y = -v0/(1+np.exp((x-R)/a))

plt.plot(x, y, &#39;b-&#39;)
plt.title(r&#39;{\bf Woods-Saxon potential}&#39;, fontsize=20)
plt.text(3, -40, r&#39;Parameters: $A=20$, $V_0=50$ [MeV]&#39;, fontdict=font)
plt.text(3, -44, r&#39;$a=0.5$ [fm], $r_0=1.25$ [fm]&#39;, fontdict=font)
plt.xlabel(r&#39;$r$ [fm]&#39;,fontsize=20)
plt.ylabel(r&#39;$V(r)$ [MeV]&#39;,fontsize=20)

# Tweak spacing to prevent clipping of ylabel
plt.subplots_adjust(left=0.15)
plt.savefig(&#39;woodsaxon.pdf&#39;, format=&#39;pdf&#39;)
</pre></div>
</div>
<p>From the plot we notice that the potential
* rapidly approaches zero as <span class="math">\(r\)</span> goes to infinity, reflecting the short-distance nature of the strong nuclear force.</p>
<ul class="simple">
<li>For large <span class="math">\(A\)</span>, it is approximately flat in the center.</li>
<li>Nucleons near the surface of the nucleus experience a large force towards the center.</li>
</ul>
<p>We have introduced a single-particle Hamiltonian</p>
<div class="math">
\[H_0=\sum_{i=1}^A \hat{h}_0(x_i) =  \sum_{i=1}^A\left(\hat{t}(x_i) + \hat{u}_{\mathrm{ext}}(x_i)\right),\]</div>
<p>with an external and central symmetric potential <span class="math">\(u_{\mathrm{ext}}(x_i)\)</span>, which is often
approximated by a harmonic oscillator potential or a Woods-Saxon potential. Being central symmetric leads to a degeneracy
in energy which is not observed experimentally. We see this from for example our discussion of separation energies and magic numbers. There are, in addition to the assumed magic numbers from a harmonic oscillator basis of <span class="math">\(2,8,20,40,70\dots\)</span> magic numbers like <span class="math">\(28\)</span>, <span class="math">\(50\)</span>, <span class="math">\(82\)</span> and <span class="math">\(126\)</span>.</p>
<p>To produce these additional numbers, we need to add a phenomenological spin-orbit force which lifts the degeneracy, that is</p>
<div class="math">
\[\hat{h}(x_i) =  \hat{t}(x_i) + \hat{u}_{\mathrm{ext}}(x_i) +\xi(\boldsymbol{r})\boldsymbol{ls}=\hat{h}_0(x_i)+\xi(\boldsymbol{r})\boldsymbol{ls}.\]</div>
<p>We have introduced a modified single-particle Hamiltonian</p>
<div class="math">
\[\hat{h}(x_i) =  \hat{t}(x_i) + \hat{u}_{\mathrm{ext}}(x_i) +\xi(\boldsymbol{r})\boldsymbol{ls}=\hat{h}_0(x_i)+\xi(\boldsymbol{r})\boldsymbol{ls}.\]</div>
<p>We can calculate the expectation value of the latter using the fact that</p>
<div class="math">
\[\xi(\boldsymbol{r})\boldsymbol{ls}=\frac{1}{2}\xi(\boldsymbol{r})\left(\boldsymbol{j}^2-\boldsymbol{l}^2-\boldsymbol{s}^2\right).\]</div>
<p>For a single-particle state with quantum numbers <span class="math">\(nlj\)</span> (we suppress <span class="math">\(s\)</span> and <span class="math">\(m_j\)</span>), with <span class="math">\(s=1/2\)</span>, we obtain the single-particle energies</p>
<div class="math">
\[\varepsilon_{nlj} = \varepsilon_{nlj}^{(0)}+\Delta\varepsilon_{nlj},\]</div>
<p>with <span class="math">\(\varepsilon_{nlj}^{(0)}\)</span> being the single-particle energy obtained with <span class="math">\(\hat{h}_0(x)\)</span> and</p>
<div class="math">
\[\Delta\varepsilon_{nlj}=\frac{C}{2}\left(j(j+1)-l(l+1)-\frac{3}{4}\right).\]</div>
<p>The spin-orbit force gives thus an additional contribution to the energy</p>
<div class="math">
\[\Delta\varepsilon_{nlj}=\frac{C}{2}\left(j(j+1)-l(l+1)-\frac{3}{4}\right),\]</div>
<p>which lifts the degeneracy we have seen before in the harmonic oscillator or Woods-Saxon potentials. The value <span class="math">\(C\)</span> is the radial
integral involving <span class="math">\(\xi(\boldsymbol{r})\)</span>. Depending on the value of <span class="math">\(j=l\pm 1/2\)</span>, we obtain</p>
<div class="math">
\[\Delta\varepsilon_{nlj=l-1/2}=\frac{C}{2}l,\]</div>
<p>or</p>
<div class="math">
\[\Delta\varepsilon_{nlj=l+1/2}=-\frac{C}{2}(l+1),\]</div>
<p>clearly lifting the degeneracy. Note well that till now we have simply postulated the spin-orbit force in <em>ad hoc</em> way.
Later, we will see how this term arises from the two-nucleon force in a natural way.</p>
<p>With the spin-orbit force, we can modify our Woods-Saxon potential to</p>
<div class="math">
\[\hat{u}_{\mathrm{ext}}(r)=-\frac{V_0}{1+\exp{(r-R)/a}}+V_{so}(r)\boldsymbol{ls},\]</div>
<p>with</p>
<div class="math">
\[V_{so}(r) = V_{so}\frac{1}{r}\frac{d f_{so}(r)}{dr},\]</div>
<p>where we have</p>
<div class="math">
\[f_{so}(r) = \frac{1}{1+\exp{(r-R_{so})/a_{so}}}.\]</div>
<p>We can also add, in case of proton, a Coulomb potential. The Woods-Saxon potential has been widely used in parametrizations of
effective single-particle potentials. <strong>However, as was the case with the harmonic oscillator, none of these potentials are linked directly to the nuclear forces</strong>. Our next step is to build a mean field based on the nucleon-nucleon interaction.
This will lead us to our first and simplest many-body theory, Hartree-Fock theory.</p>
<p>The Woods-Saxon potential does allow for closed-form or analytical solutions of the eigenvalue problem</p>
<div class="math">
\[\hat{h}_0(x_i)\psi_{\alpha}(x_i)=\varepsilon_{\alpha}\psi_{\alpha}(x_i).\]</div>
<p>For the harmonic oscillator in three dimensions we have closed-form expressions for the energies and analytical solutions for the eigenstates,
with the latter given by either Hermite polynomials (cartesian coordinates) or Laguerre polynomials (spherical coordinates).</p>
<p>To solve the above equation is however rather straightforward numerically.</p>
</div>
<div class="section" id="numerical-solution-of-the-single-particle-schroedinger-equation">
<h2>Numerical solution of the single-particle Schroedinger equation<a class="headerlink" href="#numerical-solution-of-the-single-particle-schroedinger-equation" title="Permalink to this headline">¶</a></h2>
<p>We will illustrate the numerical solution of Schroedinger&#8217;s equation by solving it for the harmonic oscillator in three dimensions.
It is straightforward to change the harmonic oscillator potential with a Woods-Saxon potential, or any other type of potentials.</p>
<p>We are interested in the solution of the radial part of Schroedinger&#8217;s equation for one nucleon.
The angular momentum part  is given by the so-called Spherical harmonics.</p>
<p>The radial equation reads</p>
<div class="math">
\[-\frac{\hbar^2}{2 m} \left ( \frac{1}{r^2} \frac{d}{dr} r^2
\frac{d}{dr} - \frac{l (l + 1)}{r^2} \right )R(r)
   + V(r) R(r) = E R(r).\]</div>
<p>In our case <span class="math">\(V(r)\)</span> is the harmonic oscillator potential <span class="math">\((1/2)kr^2\)</span> with
<span class="math">\(k=m\omega^2\)</span> and <span class="math">\(E\)</span> is
the energy of the harmonic oscillator in three dimensions.
The oscillator frequency is <span class="math">\(\omega\)</span> and the energies are</p>
<div class="math">
\[E_{nl}=  \hbar \omega \left(2n+l+\frac{3}{2}\right),\]</div>
<p>with <span class="math">\(n=0,1,2,\dots\)</span> and <span class="math">\(l=0,1,2,\dots\)</span>.</p>
<p>Since we have made a transformation to spherical coordinates it means that
<span class="math">\(r\in [0,\infty)\)</span>.
The quantum number
<span class="math">\(l\)</span> is the orbital momentum of the nucleon.   Then we substitute <span class="math">\(R(r) = (1/r) u(r)\)</span> and obtain</p>
<div class="math">
\[-\frac{\hbar^2}{2 m} \frac{d^2}{dr^2} u(r)
     + \left ( V(r) + \frac{l (l + 1)}{r^2}\frac{\hbar^2}{2 m}
                                  \right ) u(r)  = E u(r) .\]</div>
<p>The boundary conditions are <span class="math">\(u(0)=0\)</span> and <span class="math">\(u(\infty)=0\)</span>.</p>
<p>We introduce a dimensionless variable <span class="math">\(\rho = (1/\alpha) r\)</span>
where <span class="math">\(\alpha\)</span> is a constant with dimension length and get</p>
<div class="math">
\[-\frac{\hbar^2}{2 m \alpha^2} \frac{d^2}{d\rho^2} u(\rho)
     + \left ( V(\rho) + \frac{l (l + 1)}{\rho^2}
       \frac{\hbar^2}{2 m\alpha^2} \right ) u(\rho)  = E u(\rho) .\]</div>
<p>Let us specialize to <span class="math">\(l=0\)</span>.
Inserting <span class="math">\(V(\rho) = (1/2) k \alpha^2\rho^2\)</span> we end up with</p>
<div class="math">
\[-\frac{\hbar^2}{2 m \alpha^2} \frac{d^2}{d\rho^2} u(\rho)
     + \frac{k}{2} \alpha^2\rho^2u(\rho)  = E u(\rho) .\]</div>
<p>We multiply thereafter with <span class="math">\(2m\alpha^2/\hbar^2\)</span> on both sides and obtain</p>
<div class="math">
\[-\frac{d^2}{d\rho^2} u(\rho)
     + \frac{mk}{\hbar^2} \alpha^4\rho^2u(\rho)  = \frac{2m\alpha^2}{\hbar^2}E u(\rho) .\]</div>
<p>We have thus</p>
<div class="math">
\[-\frac{d^2}{d\rho^2} u(\rho)
     + \frac{mk}{\hbar^2} \alpha^4\rho^2u(\rho)  = \frac{2m\alpha^2}{\hbar^2}E u(\rho) .\]</div>
<p>The constant <span class="math">\(\alpha\)</span> can now be fixed
so that</p>
<div class="math">
\[\frac{mk}{\hbar^2} \alpha^4 = 1,\]</div>
<p>or</p>
<div class="math">
\[\alpha = \left(\frac{\hbar^2}{mk}\right)^{1/4}.\]</div>
<p>Defining</p>
<div class="math">
\[\lambda = \frac{2m\alpha^2}{\hbar^2}E,\]</div>
<p>we can rewrite Schroedinger&#8217;s equation as</p>
<div class="math">
\[-\frac{d^2}{d\rho^2} u(\rho) + \rho^2u(\rho)  = \lambda u(\rho) .\]</div>
<p>This is the first equation to solve numerically. In three dimensions
the eigenvalues for <span class="math">\(l=0\)</span> are
<span class="math">\(\lambda_0=3,\lambda_1=7,\lambda_2=11,\dots .\)</span></p>
<p>We use the standard
expression for the second derivative of a function <span class="math">\(u\)</span></p>
<div class="math" id="equation-eq:diffoperation">
<span class="eqno">(5)</span>\[         u''=\frac{u(\rho+h) -2u(\rho) +u(\rho-h)}{h^2} +O(h^2),\]</div>
<p>where <span class="math">\(h\)</span> is our step.
Next we define minimum and maximum values for the variable <span class="math">\(\rho\)</span>,
<span class="math">\(\rho_{\mathrm{min}}=0\)</span>  and <span class="math">\(\rho_{\mathrm{max}}\)</span>, respectively.
You need to check your results for the energies against different values
<span class="math">\(\rho_{\mathrm{max}}\)</span>, since we cannot set
<span class="math">\(\rho_{\mathrm{max}}=\infty\)</span>.</p>
<p>With a given number of steps, <span class="math">\(n_{\mathrm{step}}\)</span>, we then
define the step <span class="math">\(h\)</span> as</p>
<div class="math">
\[h=\frac{\rho_{\mathrm{max}}-\rho_{\mathrm{min}} }{n_{\mathrm{step}}}.\]</div>
<p>Define an arbitrary value of <span class="math">\(\rho\)</span> as</p>
<div class="math">
\[\rho_i= \rho_{\mathrm{min}} + ih \hspace{1cm} i=0,1,2,\dots , n_{\mathrm{step}}\]</div>
<p>we can rewrite the Schroedinger equation for <span class="math">\(\rho_i\)</span> as</p>
<div class="math">
\[-\frac{u(\rho_i+h) -2u(\rho_i) +u(\rho_i-h)}{h^2}+\rho_i^2u(\rho_i)  = \lambda u(\rho_i),\]</div>
<p>or in  a more compact way</p>
<div class="math">
\[-\frac{u_{i+1} -2u_i +u_{i-1}}{h^2}+\rho_i^2u_i=-\frac{u_{i+1} -2u_i +u_{i-1} }{h^2}+V_iu_i  = \lambda u_i,\]</div>
<p>where <span class="math">\(V_i=\rho_i^2\)</span> is the harmonic oscillator potential.</p>
<p>Define first the diagonal matrix element</p>
<div class="math">
\[d_i=\frac{2}{h^2}+V_i,\]</div>
<p>and the non-diagonal matrix element</p>
<div class="math">
\[e_i=-\frac{1}{h^2}.\]</div>
<p>In this case the non-diagonal matrix elements are given by a mere constant. <em>All non-diagonal matrix elements are equal</em>.</p>
<p>With these definitions the Schroedinger equation takes the following form</p>
<div class="math">
\[d_iu_i+e_{i-1}u_{i-1}+e_{i+1}u_{i+1}  = \lambda u_i,\]</div>
<p>where <span class="math">\(u_i\)</span> is unknown. We can write the
latter equation as a matrix eigenvalue problem</p>
<div class="math" id="equation-eq:sematrix">
<span class="eqno">(6)</span>\[\begin{split}         \left( \begin{array}{ccccccc} d_1 &amp; e_1 &amp; 0   &amp; 0    &amp; \dots  &amp;0     &amp; 0 \\
                                     e_1 &amp; d_2 &amp; e_2 &amp; 0    &amp; \dots  &amp;0     &amp;0 \\
                                     0   &amp; e_2 &amp; d_3 &amp; e_3  &amp;0       &amp;\dots &amp; 0\\
                                     \dots  &amp; \dots &amp; \dots &amp; \dots  &amp;\dots      &amp;\dots &amp; \dots\\
                                     0   &amp; \dots &amp; \dots &amp; \dots  &amp;\dots       &amp;d_{n_{\mathrm{step}}-2} &amp; e_{n_{\mathrm{step}}-1}\\
                                     0   &amp; \dots &amp; \dots &amp; \dots  &amp;\dots       &amp;e_{n_{\mathrm{step}}-1} &amp; d_{n_{\mathrm{step}}-1}\end{split}\]\[\begin{split}                  \end{array} \right)      \left( \begin{array}{c} u_{1} \\
                                                                   u_{2} \\
                                                                   \dots\\ \dots\\ \dots\\
                                                                   u_{n_{\mathrm{step}}-1}
                  \end{array} \right)=\lambda \left( \begin{array}{c} u_{1} \\
                                                                   u_{2} \\
                                                                   \dots\\ \dots\\ \dots\\
                                                                   u_{n_{\mathrm{step}}-1}
                  \end{array} \right)\end{split}\]</div>
<p>or if we wish to be more detailed, we can write the tridiagonal matrix as</p>
<div class="math" id="equation-eq:matrixse">
<span class="eqno">(7)</span>\[\begin{split}         \left( \begin{array}{ccccccc} \frac{2}{h^2}+V_1 &amp; -\frac{1}{h^2} &amp; 0   &amp; 0    &amp; \dots  &amp;0     &amp; 0 \\
                                     -\frac{1}{h^2} &amp; \frac{2}{h^2}+V_2 &amp; -\frac{1}{h^2} &amp; 0    &amp; \dots  &amp;0     &amp;0 \\
                                     0   &amp; -\frac{1}{h^2} &amp; \frac{2}{h^2}+V_3 &amp; -\frac{1}{h^2}  &amp;0       &amp;\dots &amp; 0\\
                                     \dots  &amp; \dots &amp; \dots &amp; \dots  &amp;\dots      &amp;\dots &amp; \dots\\
                                     0   &amp; \dots &amp; \dots &amp; \dots  &amp;\dots       &amp;\frac{2}{h^2}+V_{n_{\mathrm{step}}-2} &amp; -\frac{1}{h^2}\\
                                     0   &amp; \dots &amp; \dots &amp; \dots  &amp;\dots       &amp;-\frac{1}{h^2} &amp; \frac{2}{h^2}+V_{n_{\mathrm{step}}-1}\end{split}\]\[                  \end{array} \right)\]</div>
<p>Recall that the solutions are known via the boundary conditions at
<span class="math">\(i=n_{\mathrm{step}}\)</span> and at the other end point, that is for  <span class="math">\(\rho_0\)</span>.
The solution is zero in both cases.</p>
<p>The following python program is an example of how one can obtain the eigenvalues for a single-nucleon moving in a harmonic oscillator potential. It is rather easy to change the onebody-potential with ones like a Woods-Saxon potential.</p>
<ul class="simple">
<li>The c++ and Fortran versions of this program can be found <a class="reference external" href="https://github.com/NuclearStructure/PHY981/tree/master/doc/pub/spdata/programs">here</a>.</li>
<li>The c++  program uses the c++ library <a class="reference external" href="http://arma.sourceforge.net/">armadillo</a>.</li>
<li>To install armadillo see the <a class="reference external" href="http://www.uio.no/studier/emner/matnat/fys/FYS4411/v14/guides/installing-armadillo/">guidelines</a>.</li>
<li>For mac users I recommend using <a class="reference external" href="http://brew.sh/">*brew*</a>.</li>
<li>If you use ipython notebook, you can run c++ programs following the instructions <a class="reference external" href="http://nbviewer.ipython.org/github/dragly/cppmagic/blob/master/example.ipynb">here</a></li>
</ul>
<p>The code sets up the Hamiltonian matrix by defining the the minimun and maximum values of <span class="math">\(r\)</span> with a
maximum value of integration points.  These are set in the initialization function. It plots the
eigenfunctions of the three lowest eigenstates.</p>
<div class="highlight-text"><div class="highlight"><pre>#Program which solves the one-particle Schrodinger equation
#for a potential specified in function
#potential(). This example is for the harmonic oscillator in 3d

from  matplotlib import pyplot as plt
import numpy as np
#Function for initialization of parameters
def initialize():
    RMin = 0.0
    RMax = 10.0
    lOrbital = 0
    Dim = 400
    return RMin, RMax, lOrbital, Dim
# Here we set up the harmonic oscillator potential
def potential(r):
    return r*r

#Get the boundary, orbital momentum and number of integration points
RMin, RMax, lOrbital, Dim = initialize()

#Initialize constants
Step    = RMax/(Dim+1)
DiagConst = 2.0 / (Step*Step)
NondiagConst =  -1.0 / (Step*Step)
OrbitalFactor = lOrbital * (lOrbital + 1.0)

#Calculate array of potential values
v = np.zeros(Dim)
r = np.linspace(RMin,RMax,Dim)
for i in xrange(Dim):
    r[i] = RMin + (i+1) * Step;
    v[i] = potential(r[i]) + OrbitalFactor/(r[i]*r[i]);

#Setting up tridiagonal matrix and find eigenvectors and eigenvalues
Hamiltonian = np.zeros((Dim,Dim))
Hamiltonian[0,0] = DiagConst + v[0];
Hamiltonian[0,1] = NondiagConst;
for i in xrange(1,Dim-1):
    Hamiltonian[i,i-1]  = NondiagConst;
    Hamiltonian[i,i]    = DiagConst + v[i];
    Hamiltonian[i,i+1]  = NondiagConst;
Hamiltonian[Dim-1,Dim-2] = NondiagConst;
Hamiltonian[Dim-1,Dim-1] = DiagConst + v[Dim-1];
# diagonalize and obtain eigenvalues, not necessarily sorted
EigValues, EigVectors = np.linalg.eig(Hamiltonian)
# sort eigenvectors and eigenvalues
permute = EigValues.argsort()
EigValues = EigValues[permute]
EigVectors = EigVectors[:,permute]
# now plot the results for the three lowest lying eigenstates
for i in xrange(3):
    print EigValues[i]
FirstEigvector = EigVectors[:,0]
SecondEigvector = EigVectors[:,1]
ThirdEigvector = EigVectors[:,2]
plt.plot(r, FirstEigvector**2 ,&#39;b-&#39;,r, SecondEigvector**2 ,&#39;g-&#39;,r, ThirdEigvector**2 ,&#39;r-&#39;)
plt.axis([0,4.6,0.0, 0.025])
plt.xlabel(r&#39;$r$&#39;)
plt.ylabel(r&#39;Radial probability $r^2|R(r)|^2$&#39;)
plt.title(r&#39;Radial probability distributions for three lowest-lying states&#39;)
plt.savefig(&#39;eigenvector.pdf&#39;)
plt.savefig(&#39;eigenvector.png&#39;)
plt.show()
</pre></div>
</div>
<div class="section" id="exercise-1-masses-and-binding-energies">
<h3>Exercise 1: Masses and binding energies<a class="headerlink" href="#exercise-1-masses-and-binding-energies" title="Permalink to this headline">¶</a></h3>
<p>The data on binding energies can be found in the file bedata.dat at the github address of the <a class="reference external" href="https://github.com/NuclearStructure/PHY981/tree/master/doc/pub/spdata/programs">Nuclear Structure course at MSU, PHY981</a></p>
<p><strong>a)</strong>
Write a small program which reads in the proton and neutron numbers and the binding energies
and make a plot of all neutron separation energies for the chain of oxygen (O), calcium (Ca), nickel (Ni), tin (Sn) and lead (Pb) isotopes, that is you need to plot</p>
<div class="math">
\[S_n= BE(N,Z)-BE(N-1,Z).\]</div>
<p>Comment your results.</p>
<p><strong>b)</strong>
In the same figures, you should also include the liquid drop model results of Eq.&nbsp;(2.17) of Alex Brown&#8217;s text, namely</p>
<div class="math">
\[BE(N,Z)= \alpha_1A-\alpha_2A^{2/3}-\alpha_3\frac{Z^2}{A^{1/3}}-\alpha_4\frac{(N-Z)^2}{A},\]</div>
<p>with <span class="math">\(\alpha_1=15.49\)</span> MeV, <span class="math">\(\alpha_2=17.23\)</span> MeV, <span class="math">\(\alpha_3=0.697\)</span> MeV and <span class="math">\(\alpha_4=22.6\)</span> MeV.
Again, comment your results.</p>
<p><strong>c)</strong>
Make also a plot of the binding energies as function of <span class="math">\(A\)</span> using the data in the file on binding energies and the above liquid drop model.  Make a figure similar to figure 2.5 of Alex Brown where you set the various parameters <span class="math">\(\alpha_i=0\)</span>. Comment your results.</p>
<p><strong>d)</strong>
Use the liquid drop model to find the neutron drip lines   for Z values up to 120.
Analyze then the fluorine isotopes and find, where available the corresponding experimental data, and compare the liquid drop model predicition with experiment.
Comment your results.
A program example in C++ and the input data file <em>bedata.dat</em> can be found found at the github repository for the <a class="reference external" href="https://github.com/NuclearStructure/PHY981/tree/master/doc/pub/spdata/programs">course</a></p>
</div>
<div class="section" id="exercise-2-eigenvalues-and-eigenvectors-for-various-single-particle-potentials">
<h3>Exercise 2: Eigenvalues and eigenvectors for various single-particle potentials<a class="headerlink" href="#exercise-2-eigenvalues-and-eigenvectors-for-various-single-particle-potentials" title="Permalink to this headline">¶</a></h3>
<p>The program for finding the eigenvalues of the harmonic oscillator are in the <a class="reference external" href="https://github.com/NuclearStructure/PHY981/tree/master/doc/pub/spdata/programs">github folder</a>.</p>
<p>You can use this program to solve the exercises below, or write your own using your preferred programming language, be it python, fortran or c++ or other languages. Here I will mainly provide fortran, python and c++.</p>
<p><strong>a)</strong>
Compute the eigenvalues of the five lowest states with a given orbital momentum and oscillator frequency <span class="math">\(\omega\)</span>. Study these results as functions of the the maximum value of <span class="math">\(r\)</span> and the number of integration points <span class="math">\(n\)</span>, starting with  <span class="math">\(r_{\mathrm{max}}=10\)</span>. Compare the computed ones with the exact values and comment your results.</p>
<p><strong>b)</strong>
Plot thereafter the eigenfunctions as functions of <span class="math">\(r\)</span> for the lowest-lying state with a given orbital momentum <span class="math">\(l\)</span>.</p>
<p><strong>c)</strong>
Replace thereafter the harmonic oscillator potential with a Woods-Saxon potential using the parameters discussed above. Compute the lowest five eigenvalues and plot the eigenfunction of the lowest-lying state. How does this compare with the harmonic oscillator? Comment your results and possible implications for nuclear physics studies.</p>
</div>
<div class="section" id="exercise-3-operators-and-slater-determinants">
<h3>Exercise 3: Operators and Slater determinants<a class="headerlink" href="#exercise-3-operators-and-slater-determinants" title="Permalink to this headline">¶</a></h3>
<p>Consider the Slater determinant</p>
<div class="math">
\[\Phi_{\lambda}^{AS}(x_{1}x_{2}\dots x_{N};\alpha_{1}\alpha_{2}\dots\alpha_{N})
=\frac{1}{\sqrt{N!}}\sum_{p}(-)^{p}P\prod_{i=1}^{N}\psi_{\alpha_{i}}(x_{i}).\]</div>
<p>where <span class="math">\(P\)</span> is an operator which permutes the coordinates of two particles. We have assumed here that the
number of particles is the same as the number of available single-particle states, represented by the
greek letters <span class="math">\(\alpha_{1}\alpha_{2}\dots\alpha_{N}\)</span>.</p>
<p><strong>a)</strong>
Write  out <span class="math">\(\Phi^{AS}\)</span> for <span class="math">\(N=3\)</span>.</p>
<p><strong>b)</strong>
Show that</p>
<div class="math">
\[\int dx_{1}dx_{2}\dots dx_{N}\left\vert
\Phi_{\lambda}^{AS}(x_{1}x_{2}\dots x_{N};\alpha_{1}\alpha_{2}\dots\alpha_{N})
\right\vert^{2} = 1.\]</div>
<p><strong>c)</strong>
Define a general onebody operator <span class="math">\(\hat{F} = \sum_{i}^N\hat{f}(x_{i})\)</span> and a general  twobody operator <span class="math">\(\hat{G}=\sum_{i&gt;j}^N\hat{g}(x_{i},x_{j})\)</span> with <span class="math">\(g\)</span> being invariant under the interchange of the coordinates of particles <span class="math">\(i\)</span> and <span class="math">\(j\)</span>. Calculate the matrix elements for a two-particle Slater determinant</p>
<div class="math">
\[\langle\Phi_{\alpha_{1}\alpha_{2}}^{AS}|\hat{F}|\Phi_{\alpha_{1}\alpha_{2}}^{AS}\rangle,\]</div>
<p>and</p>
<div class="math">
\[\langle\Phi_{\alpha_{1}\alpha_{2}}^{AS}|\hat{G}|\Phi_{\alpha_{1}\alpha_{2}}^{AS}\rangle.\]</div>
<p>Explain the short-hand notation for the Slater determinant.
Which properties do you expect these operators to have in addition to an eventual permutation
symmetry?</p>
</div>
<div class="section" id="exercise-4-first-simple-shell-model-calculation">
<h3>Exercise 4: First simple shell-model calculation<a class="headerlink" href="#exercise-4-first-simple-shell-model-calculation" title="Permalink to this headline">¶</a></h3>
<p>We will now consider a simple three-level problem, depicted in the figure below. This is our first and very simple model of a possible many-nucleon (or just fermion) problem and the shell-model.
The single-particle states are labelled by the quantum number <span class="math">\(p\)</span> and can accomodate up to two single particles,  viz., every single-particle state  is doubly degenerate (you could think of this as one state having spin up and the other spin down).
We let the spacing between the doubly degenerate single-particle states be constant, with value <span class="math">\(d\)</span>.  The first state
has energy <span class="math">\(d\)</span>. There are only three available single-particle states, <span class="math">\(p=1\)</span>, <span class="math">\(p=2\)</span> and <span class="math">\(p=3\)</span>, as illustrated
in the figure.</p>
<p><strong>a)</strong>
How many two-particle Slater determinants can we construct in this space?</p>
<p>We limit ourselves to a system with only the two lowest single-particle orbits and two particles, <span class="math">\(p=1\)</span> and <span class="math">\(p=2\)</span>. We assume that we can write the Hamiltonian as</p>
<div class="math">
\[\hat{H}=\hat{H}_0+\hat{H}_I,\]</div>
<p>and that the onebody part of the Hamiltonian with single-particle operator <span class="math">\(\hat{h}_0\)</span> has the property</p>
<div class="math">
\[\hat{h}_0\psi_{p\sigma} = p\times d \psi_{p\sigma},\]</div>
<p>where we have added a spin quantum number <span class="math">\(\sigma\)</span>.
We assume also that the only two-particle states that can exist are those where two particles are in the
same state <span class="math">\(p\)</span>, as shown by the two possibilities to the left in the figure.
The two-particle matrix elements of <span class="math">\(\hat{H}_I\)</span> have all a constant value, <span class="math">\(-g\)</span>.</p>
<p><strong>b)</strong>
Show then that the Hamiltonian matrix can be written as</p>
<div class="math">
\[\begin{split}\left(\begin{array}{cc}2d-g &amp;-g \\
-g &amp;4d-g \end{array}\right),\end{split}\]</div>
<p><strong>c)</strong>
Find the eigenvalues and eigenvectors.  What is mixing of the state with two particles in <span class="math">\(p=2\)</span>  to the wave function with two-particles in <span class="math">\(p=1\)</span>? Discuss your results in terms of a linear combination of Slater determinants.</p>
<p><strong>d)</strong>
Add the possibility that the two particles can be in the state with <span class="math">\(p=3\)</span> as well and find the Hamiltonian matrix, the eigenvalues and the eigenvectors. We still insist that we only have two-particle states composed of two particles being in the same level <span class="math">\(p\)</span>. You can diagonalize numerically your <span class="math">\(3\times 3\)</span> matrix.
This simple model catches several birds with a stone. It demonstrates how we can build linear combinations
of Slater determinants and interpret these as different admixtures to a given state. It represents also the way we are going to interpret these contributions.  The two-particle states above <span class="math">\(p=1\)</span> will be interpreted as
excitations from the ground state configuration, <span class="math">\(p=1\)</span> here.  The reliability of this ansatz for the ground state,
with two particles in <span class="math">\(p=1\)</span>,
depends on the strength of the interaction <span class="math">\(g\)</span> and the single-particle spacing <span class="math">\(d\)</span>.
Finally, this model is a simple schematic ansatz for studies of pairing correlations and thereby superfluidity/superconductivity
in fermionic systems.</p>
<div class="figure" id="id3">
<a class="reference internal image-reference" href="_images/simplemodel.png"><img alt="_images/simplemodel.png" src="_images/simplemodel.png" style="width: 500px;" /></a>
<p class="caption"><span class="caption-text">Schematic plot of the possible single-particle levels with double degeneracy. The filled circles indicate occupied particle states. The spacing between each level <span class="math">\(p\)</span> is constant in this picture. We show some possible two-particle states</span></p>
</div>
</div>
</div>
</div>


          </div>
        </div>
      </div>
      <div class="sphinxsidebar">
        <div class="sphinxsidebarwrapper">
  <h3><a href="index.html">Table Of Contents</a></h3>
  <ul>
<li><a class="reference internal" href="#">Introduction and Motivation</a><ul>
<li><a class="reference internal" href="#introduction">Introduction</a></li>
<li><a class="reference internal" href="#masses-and-binding-energies">Masses and Binding energies</a></li>
<li><a class="reference internal" href="#values-and-separation-energies"><span class="math">\(Q\)</span>-values and separation energies</a></li>
<li><a class="reference internal" href="#radii">Radii</a></li>
<li><a class="reference internal" href="#definitions">Definitions</a></li>
<li><a class="reference internal" href="#a-modified-hamiltonian">A modified Hamiltonian</a></li>
<li><a class="reference internal" href="#numerical-solution-of-the-single-particle-schroedinger-equation">Numerical solution of the single-particle Schroedinger equation</a><ul>
<li><a class="reference internal" href="#exercise-1-masses-and-binding-energies">Exercise 1: Masses and binding energies</a></li>
<li><a class="reference internal" href="#exercise-2-eigenvalues-and-eigenvectors-for-various-single-particle-potentials">Exercise 2: Eigenvalues and eigenvectors for various single-particle potentials</a></li>
<li><a class="reference internal" href="#exercise-3-operators-and-slater-determinants">Exercise 3: Operators and Slater determinants</a></li>
<li><a class="reference internal" href="#exercise-4-first-simple-shell-model-calculation">Exercise 4: First simple shell-model calculation</a></li>
</ul>
</li>
</ul>
</li>
</ul>

  <h4>Previous topic</h4>
  <p class="topless"><a href="index.html"
                        title="previous chapter">Introduction and Motivation</a></p>
  <h3>This Page</h3>
  <ul class="this-page-menu">
    <li><a href="_sources/intro.txt"
           rel="nofollow">Show Source</a></li>
  </ul>
<div id="searchbox" style="display: none">
  <h3>Quick search</h3>
    <form class="search" action="search.html" method="get">
      <input type="text" name="q" size="18" />
      <input type="submit" value="Go" />
      <input type="hidden" name="check_keywords" value="yes" />
      <input type="hidden" name="area" value="default" />
    </form>
    <p class="searchtip" style="font-size: 90%">
    Enter search terms or a module, class or function name.
    </p>
</div>
<script type="text/javascript">$('#searchbox').show(0);</script>
        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="footer">
      &copy;2015, "Morten Hjorth-Jensen":"http://computationalphysics.no", National Superconducting Cyclotron Laboratory and Department of Physics and Astronomy, Michigan State University, East Lansing, MI 48824, USA & Department of Physics, University of Oslo, Oslo, Norway.
      
      |
      Powered by <a href="http://sphinx-doc.org/">Sphinx 1.3.1</a>
      &amp; <a href="https://github.com/bitprophet/alabaster">Alabaster 0.7.3</a>
      
      |
      <a href="_sources/intro.txt"
          rel="nofollow">Page source</a></li>
    </div>

    

    
  </body>
</html>